<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>LLM Hallucinations | Ray Bernard's Fine-Tuned Journal</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Reducing LLM Hallucinations: A Deep Dive into Reflection LLM and Vector Stores Raymond Bernard
Senior Engineer and Solutions Architect specializing in NAS, SAN, and NVIDIA BaseBOD H100. Passionate about Data Science, AI, and Open Source. LLM enthusiast driving innovative solutions in cloud and AI technologies.
September 8, 2024
Ray Bernard
ray.bernard@outlook.com
Video demo
Code
Large Language Models (LLMs) have become invaluable tools across various domains, from content creation to coding assistance."><meta name=generator content="Hugo 0.131.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><link rel=canonical href=http://localhost:1313/posts/llm-hallucinations/><meta property="og:url" content="http://localhost:1313/posts/llm-hallucinations/"><meta property="og:site_name" content="Ray Bernard's Fine-Tuned Journal"><meta property="og:title" content="LLM Hallucinations"><meta property="og:description" content="Reducing LLM Hallucinations: A Deep Dive into Reflection LLM and Vector Stores Raymond Bernard
Senior Engineer and Solutions Architect specializing in NAS, SAN, and NVIDIA BaseBOD H100. Passionate about Data Science, AI, and Open Source. LLM enthusiast driving innovative solutions in cloud and AI technologies.
September 8, 2024
Ray Bernard
ray.bernard@outlook.com
Video demo
Code
Large Language Models (LLMs) have become invaluable tools across various domains, from content creation to coding assistance."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-08T14:42:39-04:00"><meta property="article:modified_time" content="2024-09-08T14:42:39-04:00"><meta itemprop=name content="LLM Hallucinations"><meta itemprop=description content="Reducing LLM Hallucinations: A Deep Dive into Reflection LLM and Vector Stores Raymond Bernard
Senior Engineer and Solutions Architect specializing in NAS, SAN, and NVIDIA BaseBOD H100. Passionate about Data Science, AI, and Open Source. LLM enthusiast driving innovative solutions in cloud and AI technologies.
September 8, 2024
Ray Bernard
ray.bernard@outlook.com
Video demo
Code
Large Language Models (LLMs) have become invaluable tools across various domains, from content creation to coding assistance."><meta itemprop=datePublished content="2024-09-08T14:42:39-04:00"><meta itemprop=dateModified content="2024-09-08T14:42:39-04:00"><meta itemprop=wordCount content="1897"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLM Hallucinations"><meta name=twitter:description content="Reducing LLM Hallucinations: A Deep Dive into Reflection LLM and Vector Stores Raymond Bernard
Senior Engineer and Solutions Architect specializing in NAS, SAN, and NVIDIA BaseBOD H100. Passionate about Data Science, AI, and Open Source. LLM enthusiast driving innovative solutions in cloud and AI technologies.
September 8, 2024
Ray Bernard
ray.bernard@outlook.com
Video demo
Code
Large Language Models (LLMs) have become invaluable tools across various domains, from content creation to coding assistance."><script>(function(e,t,n,s,o,i){e.hj=e.hj||function(){(e.hj.q=e.hj.q||[]).push(arguments)},e._hjSettings={hjid:5009664,hjsv:6},o=t.getElementsByTagName("head")[0],i=t.createElement("script"),i.async=1,i.src=n+e._hjSettings.hjid+s+e._hjSettings.hjsv,o.appendChild(i)})(window,document,"https://static.hotjar.com/c/hotjar-",".js?sv=")</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-XT709SJYMZ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XT709SJYMZ")</script></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Ray Bernard's Fine-Tuned Journal</a><div class="flex-l items-center"><div class=ananke-socials><a href=https://www.github.com/raymondbernard/fine-tune-journal target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="github link" aria-label="follow on github——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.linkedin.com/in/raymond-bernard-960382/ target=_blank rel=noopener class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="My Linkedin link" aria-label="follow on My Linkedin——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.youtube.com/channel/UC-OszhqWsF1tqqECdeLI_7Q target=_blank rel=noopener class="youtube ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="youtube link" aria-label="follow on youtube——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.527 41.34c-.278.0-.478.078-.6.244-.121.156-.18.424-.18.796v.896h1.543V42.38c0-.372-.062-.64-.185-.796C42.989 41.418 42.792 41.34 42.527 41.34zM36.509 41.309c.234.0.417.076.544.23.123.155.185.383.185.682v4.584c0 .286-.053.487-.153.611-.1.127-.256.189-.47.189-.148.0-.287-.033-.421-.096-.135-.062-.274-.171-.415-.313v-5.531c.119-.122.239-.213.36-.271C36.26 41.335 36.383 41.309 36.509 41.309zm5.239 3.349v1.672c0 .468.057.792.17.974.118.181.313.269.592.269.289.0.491-.076.606-.229.114-.153.175-.489.175-1.013v-.405h1.795v.456c0 .911-.217 1.596-.657 2.059-.435.459-1.089.687-1.958.687-.781.0-1.398-.242-1.847-.731-.448-.486-.676-1.157-.676-2.014v-3.986c0-.768.249-1.398.742-1.882.493-.484 1.128-.727 1.911-.727.799.0 1.413.225 1.843.674.429.448.642 1.093.642 1.935v2.264H41.748zm-3.125 3.837c-.271.336-.669.501-1.187.501-.343.0-.646-.062-.912-.192-.267-.129-.519-.327-.746-.601v.681h-1.764V36.852h1.764v3.875c.237-.27.485-.478.748-.616.267-.143.534-.212.805-.212.554.0.975.189 1.265.565.294.379.438.933.438 1.66v4.926C39.034 47.678 38.897 48.159 38.623 48.495zM30.958 48.884v-.976c-.325.361-.658.636-1.009.822-.349.191-.686.282-1.014.282-.405.0-.705-.129-.913-.396-.201-.266-.305-.658-.305-1.189v-7.422h1.744v6.809c0 .211.037.362.107.457.077.095.196.141.358.141.128.0.292-.062.488-.188.197-.125.375-.283.542-.475v-6.744H32.7v8.878H30.958zM24.916 38.6v10.284h-1.968V38.6h-2.034v-1.748h6.036V38.6H24.916zm8.078-5.622c0-.001 12.08.018 13.514 1.45 1.439 1.435 1.455 8.514 1.455 8.555.0.0-.012 7.117-1.455 8.556C45.074 52.969 32.994 53 32.994 53s-12.079-.031-13.516-1.462c-1.438-1.435-1.441-8.502-1.441-8.556.0-.041.004-7.12 1.441-8.555 1.438-1.431 13.516-1.45 13.516-1.449zm9.526-3.723h-1.966v-1.08c-.358.397-.736.703-1.13.909-.392.208-.771.312-1.14.312-.458.0-.797-.146-1.027-.437-.229-.291-.345-.727-.345-1.311v-8.172h1.962v7.497c0 .231.045.399.127.502.08.104.216.156.399.156.143.0.327-.069.548-.206.22-.137.423-.312.605-.527v-7.422h1.966V29.255zM31.847 27.588c.139.147.339.219.6.219.266.0.476-.075.634-.223.157-.152.235-.358.235-.618v-5.327c0-.214-.08-.387-.241-.519-.16-.131-.37-.196-.628-.196-.241.0-.435.065-.586.196-.148.132-.225.305-.225.519v5.327C31.636 27.233 31.708 27.439 31.847 27.588zm-1.439-7.685c.528-.449 1.241-.674 2.132-.674.812.0 1.48.237 2.001.711.517.473.777 1.083.777 1.828v5.051c0 .836-.255 1.491-.762 1.968-.513.476-1.212.714-2.106.714-.858.0-1.547-.246-2.064-.736-.513-.492-.772-1.152-.772-1.983v-5.068C29.613 20.954 29.877 20.351 30.408 19.903zM24.262 16h-2.229l2.634 8.003v5.252h2.213v-5.5L29.454 16h-2.25l-1.366 5.298h-.139L24.262 16zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://x.com/raybernard007 target=_blank rel=noopener class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://medium.com/@raybernard007 target=_blank rel=noopener class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 170 170" viewBox="0 0 170 170" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M46.5340803 65.2157554C46.6968378 63.6076572 46.0836 62.018231 44.8828198 60.93592L32.6512605 46.2010582V44H70.6302521l29.3557423 64.380952L125.794585 44H162v2.2010582L151.542017 56.2281011C150.640424 56.9153477 150.193188 58.0448862 150.380019 59.1628454V132.837155C150.193188 133.955114 150.640424 135.084652 151.542017 135.771899l10.213352 10.027043V148H110.38282V145.798942l10.580299-10.271605c1.039682-1.039389 1.039682-1.345091 1.039682-2.934744V73.0417402l-29.4169 74.7136978H88.6106443L54.3622782 73.0417402V123.115814C54.0767278 125.221069 54.7759199 127.3406 56.2581699 128.863022L70.0186741 145.55438V147.755438H31V145.55438l13.7605042-16.691358c1.4714579-1.524946 2.1298796-3.658537 1.7735761-5.747208V65.2157554z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.facebook.com/groups/1994768487609019 target=_blank rel=noopener class="facebook ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="reddit link" aria-label="follow on reddit——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked ttu">Posts</aside><div id=sharing class="mt3 ananke-socials"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://localhost:1313/posts/llm-hallucinations/&amp;title=LLM%20Hallucinations" class="ananke-social-link linkedin no-underline" aria-label="share on My Linkedin"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href="https://twitter.com/intent/tweet?url=http://localhost:1313/posts/llm-hallucinations/&amp;text=LLM%20Hallucinations" class="ananke-social-link twitter no-underline" aria-label="share on twitter"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href="https://www.facebook.com/sharer.php?u=http://localhost:1313/posts/llm-hallucinations/" class="ananke-social-link facebook no-underline" aria-label="share on reddit"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div><h1 class="f1 athelas mt3 mb1">LLM Hallucinations</h1><time class="f6 mv4 dib tracked" datetime=2024-09-08T14:42:39-04:00>September 8, 2024</time>
<span class="f6 mv4 dib tracked">- 9 minutes read </span><span class="f6 mv4 dib tracked">- 1897 words</span></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p><img src=/images/hallucinations.png alt="alt text"></p><h1 id=reducing-llm-hallucinations-a-deep-dive-into-reflection-llm-and-vector-stores>Reducing LLM Hallucinations: A Deep Dive into Reflection LLM and Vector Stores</h1><p><strong>Raymond Bernard</strong><br>Senior Engineer and Solutions Architect specializing in NAS, SAN, and NVIDIA BaseBOD H100. Passionate about Data Science, AI, and Open Source. LLM enthusiast driving innovative solutions in cloud and AI technologies.</p><p><strong>September 8, 2024</strong><br>Ray Bernard<br><a href=mailto:ray.bernard@outlook.com>ray.bernard@outlook.com</a><br><a href=https://youtu.be/hOX9bw4BHbg>Video demo</a><br><a href=https://github.com/raymondbernard/llmplayground>Code</a></p><hr><p>Large Language Models (LLMs) have become invaluable tools across various domains, from content creation to coding assistance. However, they are not without flaws and often produce hallucinations—outputs that seem plausible but are factually incorrect. This blog explores a practical solution for reducing LLM hallucinations, focusing on a new model called the <strong>Reflection LLM</strong>. This model employs a unique approach, where it reflects internally before generating responses. We’ll dive into examples that illustrate how this mechanism works, support the open-source development of such models, and discuss how community contributions can help refine this approach.</p><p>Our goal is to provide constructive criticism to the community, aiming to improve these models by enhancing the reflection mechanism. While the Reflection LLM moves us closer to self-correcting models that deliver more accurate results, it still has limitations. In this blog, we’ll demonstrate where these limitations lie using the new Reflection LLM based on <strong>LLaMa3</strong>.</p><p>You can explore the model here:<br><strong>Reflection LLM - Ollama Reflection Llama-3.1 70B - Huggingface</strong><br><em>&ldquo;Reflection Llama-3.1 70B is (currently) the world&rsquo;s top open-source LLM, trained with a new technique called Reflection-Tuning that teaches an LLM to detect mistakes in its reasoning and correct course. The model was trained on synthetic data generated by Glaive. If you&rsquo;re training a model, Glaive is incredible — use them.&rdquo;</em> — Huggingface</p><h2 id=the-problem-with-llm-hallucinations>The Problem with LLM Hallucinations</h2><p>A common misconception is that fine-tuning alone can resolve hallucinations. Fine-tuning often tweaks a model’s style and how it responds, but it doesn’t necessarily add new factual information. Fine-tuning is useful for improving coherence or tone, but hallucinations arise when the model is confident about something it knows nothing about.</p><p>Even if we use reflection, the model will not produce new insights to issue the correct answer.</p><p>LLMs require new sources of information to provide factual accuracy. This can be done using <strong>vector stores</strong>—databases designed to store and retrieve contextually relevant data. The challenge, however, is that even with using a multi-shot example in your vector database, the Reflection LLM is prone to hallucinations and may reflect away from the correct answer.</p><h3 id=heres-how-we-can-do-it>Here&rsquo;s how we can do it:</h3><ol><li><strong>Create a Vector Store with Correct QA Examples</strong>: Include examples like the Monty Hall problem and its various forms, including the correct answer to specific cases (where the host does not reveal any information).</li><li><strong>Feed the Correct Context to the LLM</strong>: The model will retrieve the relevant example from the vector store and integrate that knowledge, reducing hallucinations.</li></ol><p>Our example will demonstrate how to achieve this.</p><hr><h2 id=even-reflection-llms-can-get-it-wrong-the-monty-hall-problem-example>Even Reflection LLMs Can Get It Wrong: The Monty Hall Problem Example</h2><p>While the Reflection LLM represents progress, it’s important to recognize that even state-of-the-art models can still falter in certain situations. A common example where LLMs frequently misinterpret the problem is a variation of the <strong>Monty Hall</strong> scenario:</p><p><em>Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a gold bar; behind the others, rotten vegetables. You pick a door, say No. 1, and the host asks, &ldquo;Do you want to pick door No. 2 instead?&rdquo; Is it to your advantage to switch your choice?</em></p><p>Even models equipped with reflection mechanisms often answer this incorrectly, treating it as the classic Monty Hall problem, where switching doors is statistically beneficial.</p><p>In the classic version, the host reveals one of the losing doors, providing new information that shifts the odds of winning from 1/3 to 2/3 if you switch doors. However, in this variation, no additional information is revealed, so the probability remains 1/3, and switching offers no advantage.</p><p>Despite this, LLMs—including Reflection LLMs—tend to assume that switching is always advantageous, hallucinating the presence of extra information that isn&rsquo;t there.</p><hr><h2 id=why-reflection-alone-is-not-enough>Why Reflection Alone Is Not Enough</h2><p>We will demonstrate the limitations of reflection mechanisms. While the Reflection LLM checks its internal understanding of the problem, it doesn’t necessarily gain new factual information unless it can access external knowledge, such as from a <strong>vector db</strong>.</p><p>Even though the model reflects on the problem, it still hallucinates because it over-relies on the pattern it learned from the classic Monty Hall problem. In this instance, the reflection process is insufficient for the model to recognize that the host doesn&rsquo;t provide any new information in this version of the problem.</p><p>To correct this, we need to go a step further.</p><h3 id=lets-play-with-some-python-code-to-illustrate-our-premise>Let&rsquo;s Play with Some Python Code to Illustrate Our Premise.</h3><h4 id=baseline-model-with-no-external-information>Baseline Model with No External Information</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> ollama
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> chromadb
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>client <span style=color:#f92672>=</span> chromadb<span style=color:#f92672>.</span>Client()
</span></span><span style=display:flex><span>convo <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># replace the message_history with one-shot and multi-shot examples </span>
</span></span><span style=display:flex><span>message_history <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#39;What is my name?&#39;</span>, <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#39;Your name is Ray Bernard?&#39;</span>},
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>2</span>, <span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#39;Ray Bernard owns two cats?&#39;</span>, <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#39;Lucy and Penny&#39;</span>},
</span></span><span style=display:flex><span>    {<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>3</span>, <span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#39;Where is Ray Bernard’s astrological sign?&#39;</span>, <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#39;Virgo&#39;</span>}
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Vector database creation and embedding retrieval functions</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_vector_db</span>(conversations):
</span></span><span style=display:flex><span>    vector_db_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;conversations&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>        client<span style=color:#f92672>.</span>delete_collection(name<span style=color:#f92672>=</span>vector_db_name)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>ValueError</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>pass</span>  <span style=color:#75715e># Handle collection not existing</span>
</span></span><span style=display:flex><span>    vector_db <span style=color:#f92672>=</span> client<span style=color:#f92672>.</span>create_collection(name<span style=color:#f92672>=</span>vector_db_name)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> c <span style=color:#f92672>in</span> conversations:
</span></span><span style=display:flex><span>        serialized_convo <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;prompt:</span><span style=color:#e6db74>{</span>c[<span style=color:#e6db74>&#34;prompt&#34;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74> response:</span><span style=color:#e6db74>{</span>c[<span style=color:#e6db74>&#34;response&#34;</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>
</span></span><span style=display:flex><span>        response <span style=color:#f92672>=</span> ollama<span style=color:#f92672>.</span>embeddings(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;nomic-embed-text&#39;</span>, prompt<span style=color:#f92672>=</span>serialized_convo)
</span></span><span style=display:flex><span>        embedding <span style=color:#f92672>=</span> response[<span style=color:#e6db74>&#39;embedding&#39;</span>]
</span></span><span style=display:flex><span>        vector_db<span style=color:#f92672>.</span>add(ids<span style=color:#f92672>=</span>[str(c[<span style=color:#e6db74>&#39;id&#39;</span>])], embeddings<span style=color:#f92672>=</span>[embedding], documents<span style=color:#f92672>=</span>[serialized_convo])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>retrieve_embedding</span>(prompt):
</span></span><span style=display:flex><span>    response <span style=color:#f92672>=</span> ollama<span style=color:#f92672>.</span>embeddings(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;nomic-embed-text&#39;</span>, prompt<span style=color:#f92672>=</span>prompt)
</span></span><span style=display:flex><span>    prompt_embedding <span style=color:#f92672>=</span> response[<span style=color:#e6db74>&#39;embedding&#39;</span>]
</span></span><span style=display:flex><span>    vector_db <span style=color:#f92672>=</span> client<span style=color:#f92672>.</span>get_collection(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;conversations&#39;</span>)
</span></span><span style=display:flex><span>    results <span style=color:#f92672>=</span> vector_db<span style=color:#f92672>.</span>query(query_embeddings<span style=color:#f92672>=</span>[prompt_embedding], n_results<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> results[<span style=color:#e6db74>&#39;documents&#39;</span>][<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Using LLama3 to generate responses without vector store context</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>stream_response</span>(prompt):
</span></span><span style=display:flex><span>    convo<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#39;role&#39;</span>: <span style=color:#e6db74>&#39;user&#39;</span>, <span style=color:#e6db74>&#39;content&#39;</span>: prompt})
</span></span><span style=display:flex><span>    response <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># comment this section to remove llama3 </span>
</span></span><span style=display:flex><span>    stream <span style=color:#f92672>=</span> ollama<span style=color:#f92672>.</span>chat(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;llama3&#39;</span>, messages<span style=color:#f92672>=</span>convo, stream<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># uncomment the below to use the refection LLM </span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># stream = ollama.chat(model=&#39;reflection&#39;, messages=convo, stream=True)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> chunk <span style=color:#f92672>in</span> stream:
</span></span><span style=display:flex><span>        content <span style=color:#f92672>=</span> chunk[<span style=color:#e6db74>&#39;message&#39;</span>][<span style=color:#e6db74>&#39;content&#39;</span>]
</span></span><span style=display:flex><span>        response <span style=color:#f92672>+=</span> content
</span></span><span style=display:flex><span>        print(content, end<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>, flush<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    convo<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#39;role&#39;</span>: <span style=color:#e6db74>&#39;assistant&#39;</span>, <span style=color:#e6db74>&#39;content&#39;</span>: response}) 
</span></span></code></pre></div><h4 id=observation>Observation:</h4><p>Without additional information, the model confidently hallucinates. It &ldquo;knows&rdquo; the user’s name and the other facts used in our vector store. However, it fails to get the correct answer to the variation of the Monty Hall problem.</p><hr><h3 id=implementing-one-shot-learning-with-a-vector-store>Implementing One-Shot Learning with a Vector Store</h3><p>In this example, we introduce one-shot learning by querying the vector store to retrieve relevant information. However, despite being provided with some context, the model can still hallucinate or overestimate its knowledge. To test this, you can replace the message_history in the code and run it again.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>message_history <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span> {<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#34;&#34;&#34;Suppose you’re on a game show, and you’re given the choice of three doors: Behind one  door is a gold bar; behind the others, rotten vegetables. You pick a door, say No. 1, and the host asks you “Do you want to pick door No. 2 instead?” Is it to your advantage to switch your choice?&#34;&#34;&#34;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#34;&#34;&#34;It is not an advantage to switch. It makes no difference if I switch or not because no additional material information has been provided since the initial choice.&#34;&#34;&#34;</span>},
</span></span><span style=display:flex><span> {<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#39;Ray Bernard owns two cats?&#39;</span>, 
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#39;Lucy and Penny&#39;</span>},
</span></span><span style=display:flex><span> {<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>3</span>, 
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#39;Where is Ray Bernard’s astrological sign?&#39;</span>, 
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#39;Virgo&#39;</span>}
</span></span><span style=display:flex><span>] 
</span></span></code></pre></div><p>Observation: I noticed that the model gets the answer right with just a one-shot example. One-shot learning means the model only needs a single example to understand and correctly respond to the problem. In this case, I’m using LLama3, and it accurately solved the task with just that single example.</p><hr><h3 id=multi-shot-learning-with-reflection-llm>Multi-Shot Learning with Reflection LLM</h3><p>Using Multi-Shot Learning, hallucinations are greatly reduced by comparing different context sources in the vector database before deciding. Now, replace the message_history with the example below.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>message_history <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#34;&#34;&#34;Suppose you’re on a
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    game show, and you’re given the choice of three doors: Behind one door is a gold bar; behind the others, rotten vegetables. You pick a door, say No. 1, and the host asks you “Do you want to pick door No. 2 instead?” Is it to your advantage to switch your choice?&#34;&#34;&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#34;&#34;&#34;It is not an advantage to switch. It makes no difference if I switch or not because no additional material information has been provided since the initial choice.&#34;&#34;&#34;</span>},
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#34;&#34;&#34;Suppose you’re on a
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    game show, and you’re given the choice of three doors: Behind one door is a gold bar; behind the others, rotten vegetables. You pick a door, say No. 1, and the host asks you “Do you want to pick door No. 2 instead?” Is it to your advantage to switch your choice?&#34;&#34;&#34;</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#39;the host has not revealed any new information&#39;</span>},
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;id&#39;</span>: <span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;prompt&#39;</span>: <span style=color:#e6db74>&#39;User: What is my name&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;response&#39;</span>: <span style=color:#e6db74>&#39;Ray Bernard&#39;</span>}
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>Observation: By leveraging a vector store with accurate QA examples in a multi-shot approach, the LLM can retrieve the specific context of the problem. In our Monty Hall variation, the model accurately understands that the host hasn’t revealed any new information, meaning switching doors offers no advantage. Use multi-shot only if the model gets it wrong, as this will help improve its accuracy.</p><hr><h3 id=reflection-llm-test-with-multi-shot-example>Reflection LLM Test with Multi-Shot Example</h3><p>For our final example, let&rsquo;s use the Reflection LLM along with a multi-shot message_history to see if we can achieve better results. In my tests, the Reflection LLM failed even though multi-shot examples were provided.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span> <span style=color:#75715e>#comment this section to remove llama3 </span>
</span></span><span style=display:flex><span><span style=color:#75715e># stream = ollama.chat(model=&#39;llama3&#39;, messages=convo, stream=True)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># please uncomment the below to use the refection LLM </span>
</span></span><span style=display:flex><span>stream <span style=color:#f92672>=</span> ollama<span style=color:#f92672>.</span>chat(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;reflection&#39;</span>, messages<span style=color:#f92672>=</span>convo, stream<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><p>Observation: The Reflection LLM may initially offer the correct answer, but once it engages in the reflection process, it can overanalyze the problem and fail to recognize its own mistakes. Instead of adjusting, it tends to revert to the patterns it was originally trained on. As a result, it ultimately arrives at the wrong conclusion.</p><hr><h2 id=conclusion>Conclusion</h2><p>The release of <strong>Reflection LLM</strong> is an exciting development in the battle against LLM hallucinations and improving the overall quality of the response. However, reflection is not new and can be accomplished in many other ways. Lots of agentic frameworks have this built in. Reflection does come at a price though with respect to system performance and token consumption. It sometimes will go off the rails, going off-topic at times. But overall, this is a great approach and will improve with the advent of better models.</p><p>So how can Reflection LLM address this issue? The solution lies in prioritizing factual information from the vector store and only activating the reflection mechanism when no relevant context is available. This approach could be a valuable enhancement for the team behind Reflection LLM to consider in future updates, ensuring the model focuses on retrieving accurate information before reflecting.</p><p>Overall, I am very grateful to the open-source community and like to thank the team Matt Shumer and Sahil Chaudhary at Glaive.ai for releasing <strong>Refection LLM</strong> to the open-source community. I believe the community will play a crucial role in refining these methods, and we encourage further experimentation and development in this area. As we move forward, it&rsquo;s clear that reducing hallucinations is about more than just fine-tuning or reflection—it&rsquo;s about giving models access to accurate, contextually relevant information.</p><p>— <strong>Ray Bernard</strong><br><a href=mailto:ray.bernard@outlook.com>ray.bernard@outlook.com</a></p><hr><h2 id=references>References</h2><ul><li>Williams, S., & Huckle, J. (2024). <em>Easy Problems That LLMs Get Wrong</em>. arXiv preprint arXiv:2405.19616. <a href=https://doi.org/10.48550/arXiv.2405.19616>https://doi.org/10.48550/arXiv.2405.19616</a></li><li>Ai Austin. (2024, July 11). Local UNLIMITED Memory Ai Agent | Ollama RAG Crash Course [Video]. YouTube. <a href="https://www.youtube.com/watch?v=5xPvsMX2q2M">https://www.youtube.com/watch?v=5xPvsMX2q2M</a></li></ul><hr><p>#LLM #ReflectionLLM #Llama3_70B #AIHallucinations #VectorStore #MultiShotLearning #OneShotLearning #MontyHallProblem #OpenSourceAI #AITraining #AIDevelopment #ReducingHallucinations #FineTuning #GlaiveAI #Ollama</p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=http://localhost:1313/>&copy; Ray Bernard's Fine-Tuned Journal 2024</a><div><div class=ananke-socials><a href=https://www.github.com/raymondbernard/fine-tune-journal target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="github link" aria-label="follow on github——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.linkedin.com/in/raymond-bernard-960382/ target=_blank rel=noopener class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="My Linkedin link" aria-label="follow on My Linkedin——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.youtube.com/channel/UC-OszhqWsF1tqqECdeLI_7Q target=_blank rel=noopener class="youtube ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="youtube link" aria-label="follow on youtube——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.527 41.34c-.278.0-.478.078-.6.244-.121.156-.18.424-.18.796v.896h1.543V42.38c0-.372-.062-.64-.185-.796C42.989 41.418 42.792 41.34 42.527 41.34zM36.509 41.309c.234.0.417.076.544.23.123.155.185.383.185.682v4.584c0 .286-.053.487-.153.611-.1.127-.256.189-.47.189-.148.0-.287-.033-.421-.096-.135-.062-.274-.171-.415-.313v-5.531c.119-.122.239-.213.36-.271C36.26 41.335 36.383 41.309 36.509 41.309zm5.239 3.349v1.672c0 .468.057.792.17.974.118.181.313.269.592.269.289.0.491-.076.606-.229.114-.153.175-.489.175-1.013v-.405h1.795v.456c0 .911-.217 1.596-.657 2.059-.435.459-1.089.687-1.958.687-.781.0-1.398-.242-1.847-.731-.448-.486-.676-1.157-.676-2.014v-3.986c0-.768.249-1.398.742-1.882.493-.484 1.128-.727 1.911-.727.799.0 1.413.225 1.843.674.429.448.642 1.093.642 1.935v2.264H41.748zm-3.125 3.837c-.271.336-.669.501-1.187.501-.343.0-.646-.062-.912-.192-.267-.129-.519-.327-.746-.601v.681h-1.764V36.852h1.764v3.875c.237-.27.485-.478.748-.616.267-.143.534-.212.805-.212.554.0.975.189 1.265.565.294.379.438.933.438 1.66v4.926C39.034 47.678 38.897 48.159 38.623 48.495zM30.958 48.884v-.976c-.325.361-.658.636-1.009.822-.349.191-.686.282-1.014.282-.405.0-.705-.129-.913-.396-.201-.266-.305-.658-.305-1.189v-7.422h1.744v6.809c0 .211.037.362.107.457.077.095.196.141.358.141.128.0.292-.062.488-.188.197-.125.375-.283.542-.475v-6.744H32.7v8.878H30.958zM24.916 38.6v10.284h-1.968V38.6h-2.034v-1.748h6.036V38.6H24.916zm8.078-5.622c0-.001 12.08.018 13.514 1.45 1.439 1.435 1.455 8.514 1.455 8.555.0.0-.012 7.117-1.455 8.556C45.074 52.969 32.994 53 32.994 53s-12.079-.031-13.516-1.462c-1.438-1.435-1.441-8.502-1.441-8.556.0-.041.004-7.12 1.441-8.555 1.438-1.431 13.516-1.45 13.516-1.449zm9.526-3.723h-1.966v-1.08c-.358.397-.736.703-1.13.909-.392.208-.771.312-1.14.312-.458.0-.797-.146-1.027-.437-.229-.291-.345-.727-.345-1.311v-8.172h1.962v7.497c0 .231.045.399.127.502.08.104.216.156.399.156.143.0.327-.069.548-.206.22-.137.423-.312.605-.527v-7.422h1.966V29.255zM31.847 27.588c.139.147.339.219.6.219.266.0.476-.075.634-.223.157-.152.235-.358.235-.618v-5.327c0-.214-.08-.387-.241-.519-.16-.131-.37-.196-.628-.196-.241.0-.435.065-.586.196-.148.132-.225.305-.225.519v5.327C31.636 27.233 31.708 27.439 31.847 27.588zm-1.439-7.685c.528-.449 1.241-.674 2.132-.674.812.0 1.48.237 2.001.711.517.473.777 1.083.777 1.828v5.051c0 .836-.255 1.491-.762 1.968-.513.476-1.212.714-2.106.714-.858.0-1.547-.246-2.064-.736-.513-.492-.772-1.152-.772-1.983v-5.068C29.613 20.954 29.877 20.351 30.408 19.903zM24.262 16h-2.229l2.634 8.003v5.252h2.213v-5.5L29.454 16h-2.25l-1.366 5.298h-.139L24.262 16zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://x.com/raybernard007 target=_blank rel=noopener class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://medium.com/@raybernard007 target=_blank rel=noopener class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 170 170" viewBox="0 0 170 170" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M46.5340803 65.2157554C46.6968378 63.6076572 46.0836 62.018231 44.8828198 60.93592L32.6512605 46.2010582V44H70.6302521l29.3557423 64.380952L125.794585 44H162v2.2010582L151.542017 56.2281011C150.640424 56.9153477 150.193188 58.0448862 150.380019 59.1628454V132.837155C150.193188 133.955114 150.640424 135.084652 151.542017 135.771899l10.213352 10.027043V148H110.38282V145.798942l10.580299-10.271605c1.039682-1.039389 1.039682-1.345091 1.039682-2.934744V73.0417402l-29.4169 74.7136978H88.6106443L54.3622782 73.0417402V123.115814C54.0767278 125.221069 54.7759199 127.3406 56.2581699 128.863022L70.0186741 145.55438V147.755438H31V145.55438l13.7605042-16.691358c1.4714579-1.524946 2.1298796-3.658537 1.7735761-5.747208V65.2157554z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.facebook.com/groups/1994768487609019 target=_blank rel=noopener class="facebook ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="reddit link" aria-label="follow on reddit——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>