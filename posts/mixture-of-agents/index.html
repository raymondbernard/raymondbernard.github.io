<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Mixture of Agents | Ray Bernard's Fine Tuned Journal</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="How Mixture-of-Agents Enhances Large Language Model Capabilities Introduction In recent years, Large Language Models (LLMs) have significantly advanced the field of natural language understanding and generation. These models, pre-trained on vast datasets and fine-tuned to align with human preferences, have demonstrated impressive capabilities. However, the rapid growth in the number of LLMs and their diverse strengths has presented a new challenge: how to effectively harness the collective expertise of multiple LLMs."><meta name=generator content="Hugo 0.126.2"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><link rel=canonical href=http://localhost:1313/posts/mixture-of-agents/><meta property="og:url" content="http://localhost:1313/posts/mixture-of-agents/"><meta property="og:site_name" content="Ray Bernard's Fine Tuned Journal"><meta property="og:title" content="Mixture of Agents"><meta property="og:description" content="How Mixture-of-Agents Enhances Large Language Model Capabilities Introduction In recent years, Large Language Models (LLMs) have significantly advanced the field of natural language understanding and generation. These models, pre-trained on vast datasets and fine-tuned to align with human preferences, have demonstrated impressive capabilities. However, the rapid growth in the number of LLMs and their diverse strengths has presented a new challenge: how to effectively harness the collective expertise of multiple LLMs."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-21T16:05:44-04:00"><meta property="article:modified_time" content="2024-06-21T16:05:44-04:00"><meta itemprop=name content="Mixture of Agents"><meta itemprop=description content="How Mixture-of-Agents Enhances Large Language Model Capabilities Introduction In recent years, Large Language Models (LLMs) have significantly advanced the field of natural language understanding and generation. These models, pre-trained on vast datasets and fine-tuned to align with human preferences, have demonstrated impressive capabilities. However, the rapid growth in the number of LLMs and their diverse strengths has presented a new challenge: how to effectively harness the collective expertise of multiple LLMs."><meta itemprop=datePublished content="2024-06-21T16:05:44-04:00"><meta itemprop=dateModified content="2024-06-21T16:05:44-04:00"><meta itemprop=wordCount content="1204"><meta name=twitter:card content="summary"><meta name=twitter:title content="Mixture of Agents"><meta name=twitter:description content="How Mixture-of-Agents Enhances Large Language Model Capabilities Introduction In recent years, Large Language Models (LLMs) have significantly advanced the field of natural language understanding and generation. These models, pre-trained on vast datasets and fine-tuned to align with human preferences, have demonstrated impressive capabilities. However, the rapid growth in the number of LLMs and their diverse strengths has presented a new challenge: how to effectively harness the collective expertise of multiple LLMs."><script>(function(e,t,n,s,o,i){e.hj=e.hj||function(){(e.hj.q=e.hj.q||[]).push(arguments)},e._hjSettings={hjid:5009664,hjsv:6},o=t.getElementsByTagName("head")[0],i=t.createElement("script"),i.async=1,i.src=n+e._hjSettings.hjid+s+e._hjSettings.hjsv,o.appendChild(i)})(window,document,"https://static.hotjar.com/c/hotjar-",".js?sv=")</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-XT709SJYMZ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XT709SJYMZ")</script></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Ray Bernard's Fine Tuned Journal</a><div class="flex-l items-center"><div class=ananke-socials><a href=https://www.github.com/raymondbernard/fine-tune-journal target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="github link" aria-label="follow on github——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.linkedin.com/in/raymond-bernard-960382/ target=_blank rel=noopener class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="My Linkedin link" aria-label="follow on My Linkedin——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.youtube.com/channel/UC-OszhqWsF1tqqECdeLI_7Q target=_blank rel=noopener class="youtube ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="youtube link" aria-label="follow on youtube——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.527 41.34c-.278.0-.478.078-.6.244-.121.156-.18.424-.18.796v.896h1.543V42.38c0-.372-.062-.64-.185-.796C42.989 41.418 42.792 41.34 42.527 41.34zM36.509 41.309c.234.0.417.076.544.23.123.155.185.383.185.682v4.584c0 .286-.053.487-.153.611-.1.127-.256.189-.47.189-.148.0-.287-.033-.421-.096-.135-.062-.274-.171-.415-.313v-5.531c.119-.122.239-.213.36-.271C36.26 41.335 36.383 41.309 36.509 41.309zm5.239 3.349v1.672c0 .468.057.792.17.974.118.181.313.269.592.269.289.0.491-.076.606-.229.114-.153.175-.489.175-1.013v-.405h1.795v.456c0 .911-.217 1.596-.657 2.059-.435.459-1.089.687-1.958.687-.781.0-1.398-.242-1.847-.731-.448-.486-.676-1.157-.676-2.014v-3.986c0-.768.249-1.398.742-1.882.493-.484 1.128-.727 1.911-.727.799.0 1.413.225 1.843.674.429.448.642 1.093.642 1.935v2.264H41.748zm-3.125 3.837c-.271.336-.669.501-1.187.501-.343.0-.646-.062-.912-.192-.267-.129-.519-.327-.746-.601v.681h-1.764V36.852h1.764v3.875c.237-.27.485-.478.748-.616.267-.143.534-.212.805-.212.554.0.975.189 1.265.565.294.379.438.933.438 1.66v4.926C39.034 47.678 38.897 48.159 38.623 48.495zM30.958 48.884v-.976c-.325.361-.658.636-1.009.822-.349.191-.686.282-1.014.282-.405.0-.705-.129-.913-.396-.201-.266-.305-.658-.305-1.189v-7.422h1.744v6.809c0 .211.037.362.107.457.077.095.196.141.358.141.128.0.292-.062.488-.188.197-.125.375-.283.542-.475v-6.744H32.7v8.878H30.958zM24.916 38.6v10.284h-1.968V38.6h-2.034v-1.748h6.036V38.6H24.916zm8.078-5.622c0-.001 12.08.018 13.514 1.45 1.439 1.435 1.455 8.514 1.455 8.555.0.0-.012 7.117-1.455 8.556C45.074 52.969 32.994 53 32.994 53s-12.079-.031-13.516-1.462c-1.438-1.435-1.441-8.502-1.441-8.556.0-.041.004-7.12 1.441-8.555 1.438-1.431 13.516-1.45 13.516-1.449zm9.526-3.723h-1.966v-1.08c-.358.397-.736.703-1.13.909-.392.208-.771.312-1.14.312-.458.0-.797-.146-1.027-.437-.229-.291-.345-.727-.345-1.311v-8.172h1.962v7.497c0 .231.045.399.127.502.08.104.216.156.399.156.143.0.327-.069.548-.206.22-.137.423-.312.605-.527v-7.422h1.966V29.255zM31.847 27.588c.139.147.339.219.6.219.266.0.476-.075.634-.223.157-.152.235-.358.235-.618v-5.327c0-.214-.08-.387-.241-.519-.16-.131-.37-.196-.628-.196-.241.0-.435.065-.586.196-.148.132-.225.305-.225.519v5.327C31.636 27.233 31.708 27.439 31.847 27.588zm-1.439-7.685c.528-.449 1.241-.674 2.132-.674.812.0 1.48.237 2.001.711.517.473.777 1.083.777 1.828v5.051c0 .836-.255 1.491-.762 1.968-.513.476-1.212.714-2.106.714-.858.0-1.547-.246-2.064-.736-.513-.492-.772-1.152-.772-1.983v-5.068C29.613 20.954 29.877 20.351 30.408 19.903zM24.262 16h-2.229l2.634 8.003v5.252h2.213v-5.5L29.454 16h-2.25l-1.366 5.298h-.139L24.262 16zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://x.com/raybernard007 target=_blank rel=noopener class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://medium.com/@raybernard007 target=_blank rel=noopener class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 170 170" viewBox="0 0 170 170" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M46.5340803 65.2157554C46.6968378 63.6076572 46.0836 62.018231 44.8828198 60.93592L32.6512605 46.2010582V44H70.6302521l29.3557423 64.380952L125.794585 44H162v2.2010582L151.542017 56.2281011C150.640424 56.9153477 150.193188 58.0448862 150.380019 59.1628454V132.837155C150.193188 133.955114 150.640424 135.084652 151.542017 135.771899l10.213352 10.027043V148H110.38282V145.798942l10.580299-10.271605c1.039682-1.039389 1.039682-1.345091 1.039682-2.934744V73.0417402l-29.4169 74.7136978H88.6106443L54.3622782 73.0417402V123.115814C54.0767278 125.221069 54.7759199 127.3406 56.2581699 128.863022L70.0186741 145.55438V147.755438H31V145.55438l13.7605042-16.691358c1.4714579-1.524946 2.1298796-3.658537 1.7735761-5.747208V65.2157554z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.reddit.com/user/OpenAITutor/ target=_blank rel=noopener class="reddit ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="reddit link" aria-label="follow on reddit——Opens in a new window">reddit
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked ttu">Posts</aside><div id=sharing class="mt3 ananke-socials"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://localhost:1313/posts/mixture-of-agents/&amp;title=Mixture%20of%20Agents" class="ananke-social-link linkedin no-underline" aria-label="share on My Linkedin"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href="https://twitter.com/intent/tweet?url=http://localhost:1313/posts/mixture-of-agents/&amp;text=Mixture%20of%20Agents" class="ananke-social-link twitter no-underline" aria-label="share on twitter"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div><h1 class="f1 athelas mt3 mb1">Mixture of Agents</h1><time class="f6 mv4 dib tracked" datetime=2024-06-21T16:05:44-04:00>June 21, 2024</time>
<span class="f6 mv4 dib tracked">- 6 minutes read </span><span class="f6 mv4 dib tracked">- 1204 words</span></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h3 id=how-mixture-of-agents-enhances-large-language-model-capabilities>How Mixture-of-Agents Enhances Large Language Model Capabilities</h3><hr><h2 id=introduction>Introduction</h2><p>In recent years, Large Language Models (LLMs) have significantly advanced the field of natural language understanding and generation. These models, pre-trained on vast datasets and fine-tuned to align with human preferences, have demonstrated impressive capabilities. However, the rapid growth in the number of LLMs and their diverse strengths has presented a new challenge: how to effectively harness the collective expertise of multiple LLMs. This is where the Mixture-of-Agents (MoA) methodology comes into play, offering a promising solution to enhance the capabilities of LLMs through collaboration.</p><p>In a significant leap forward for AI, Together AI has introduced an innovative Mixture of Agents (MoA) approach, Together MoA. This new model harnesses the collective strengths of multiple large language models (LLMs) to enhance state-of-the-art quality and performance, setting new benchmarks in AI.</p><h2 id=understanding-the-mixture-of-agents-moa-methodology>Understanding the Mixture-of-Agents (MoA) Methodology</h2><h3 id=definition-and-concept>Definition and Concept</h3><p>The Mixture-of-Agents (MoA) methodology is an innovative approach that leverages the strengths of multiple LLMs to enhance overall performance. Unlike traditional single-model approaches, MoA constructs a layered architecture where each layer consists of multiple LLM agents. Each agent processes the outputs from the previous layer&rsquo;s agents as auxiliary information, iteratively refining the responses. This collaborative framework allows MoA to achieve state-of-the-art performance by combining the diverse capabilities of different LLMs.</p><h3 id=how-moa-differs-from-traditional-approaches>How MoA Differs from Traditional Approaches</h3><p>Traditional LLM approaches typically involve a single model trained on extensive data to handle various tasks. While effective, these models face limitations in scalability and specialization. Scaling up a single model is costly and time-consuming, often requiring retraining on massive datasets. In contrast, MoA capitalizes on the inherent strengths of multiple LLMs, distributing tasks among specialized agents and iteratively refining their outputs. This not only improves performance but also offers a cost-effective and scalable solution.</p><h2 id=the-collaborativeness-of-llms>The Collaborativeness of LLMs</h2><h3 id=concept-of-collaborativeness-in-llms>Concept of Collaborativeness in LLMs</h3><p>A key insight driving the MoA methodology is the concept of collaborativeness among LLMs. This refers to the phenomenon where LLMs generate better responses when they can reference outputs from other models. This collaborativeness is evident even when the auxiliary responses are of lower quality than what an individual LLM could produce independently. By leveraging this phenomenon, MoA enhances the overall response quality through iterative refinement and synthesis.</p><h3 id=benefits-of-collaborative-llm-responses>Benefits of Collaborative LLM Responses</h3><p>The collaborativeness of LLMs offers several benefits. Firstly, it allows for the integration of diverse perspectives and strengths, leading to more robust and comprehensive responses. Secondly, it mitigates the limitations of individual models, as the collective expertise can cover a broader range of tasks and scenarios. Lastly, this collaborative approach improves the adaptability and flexibility of LLMs, enabling them to handle complex and varied inputs more effectively.</p><h2 id=detailed-structure-of-the-mixture-of-agents>Detailed Structure of the Mixture-of-Agents</h2><h3 id=layered-architecture>Layered Architecture</h3><p>MoA employs a layered architecture, with each layer comprising several LLM agents. These agents utilize outputs from the previous layer as auxiliary information to generate refined responses. This method allows MoA to integrate diverse capabilities and insights from various models, resulting in a more robust and versatile combined model. The implementation has proven successful, achieving a remarkable score of 65.1% on the AlpacaEval 2.0 benchmark, surpassing the previous leader, GPT-4o, which scored 57.5%.</p><p><img src=/images/moa.png alt="Mixture-of-Agents Structure"></p><h3 id=the-role-of-proposers-and-aggregators-in-moa>The Role of Proposers and Aggregators in MoA</h3><p>A critical insight driving the development of MoA is the concept of “collaborativeness” among LLMs. This phenomenon suggests that an LLM tends to generate better responses when presented with outputs from other models, even if those models are less capable. By leveraging this insight, MoA’s architecture categorizes models into “proposers” and “aggregators.” Proposers generate initial reference responses, offering nuanced and diverse perspectives, while aggregators synthesize these responses into high-quality outputs. This iterative process continues through several layers until a comprehensive and refined response is achieved.</p><h2 id=performance-metrics-and-benchmarking>Performance Metrics and Benchmarking</h2><h3 id=benchmarking-results>Benchmarking Results</h3><p>The Together MoA framework has been rigorously tested on multiple benchmarks, including AlpacaEval 2.0, MT-Bench, and FLASK. The results are impressive, with Together MoA achieving top positions on the AlpacaEval 2.0 and MT-Bench leaderboards. Notably, on AlpacaEval 2.0, Together MoA achieved a 7.6% absolute improvement margin from 57.5% (GPT-4o) to 65.1% using only open-source models. This demonstrates the model’s superior performance compared to closed-source alternatives.</p><p><img src=/images/alpaca_and_mtbench.png alt="AlpacaEval 2.0 and MT-Bench Results"></p><h3 id=state-of-the-art-performance-and-cost-effectiveness>State-of-the-Art Performance and Cost-Effectiveness</h3><p>In addition to its technical success, Together MoA is designed with cost-effectiveness in mind. By analyzing the cost-performance trade-offs, the research indicates that the Together MoA configuration provides the best balance, offering high-quality results at a reasonable cost. This is particularly evident in the Together MoA-Lite configuration, which, despite having fewer layers, matches GPT-4o in cost while achieving superior quality.</p><h2 id=broader-impact-and-applications>Broader Impact and Applications</h2><h3 id=contributions-from-the-open-source-ai-community>Contributions from the Open-Source AI Community</h3><p>MoA’s success is attributed to the collaborative efforts of several organizations in the open-source AI community, including Meta AI, Mistral AI, Microsoft, Alibaba Cloud, and Databricks. Their contributions to developing models like Meta Llama 3, Mixtral, WizardLM, Qwen, and DBRX have been instrumental in this achievement. Additionally, benchmarks like AlpacaEval, MT-Bench, and FLASK, developed by Tatsu Labs, LMSYS, and KAIST AI, played a crucial role in evaluating MoA’s performance.</p><p><img src=/images/flask.png alt="FLASK Benchmark Results"></p><h3 id=future-directions-and-research>Future Directions and Research</h3><p>Looking ahead, Together AI plans to further optimize the MoA architecture by exploring various model choices, prompts, and configurations. One key area of focus will be reducing the latency of the time to the first token, which is an exciting future direction for this research. They aim to enhance MoA’s capabilities in reasoning-focused tasks, further solidifying its position as a leader in AI innovation.</p><h3 id=broader-impact-and-applications-1>Broader Impact and Applications</h3><p>Currently, you can run Together MoA on Together AI or locally. Ray Bernard has ported this to work on Grog AI. Groq is the AI infrastructure company that builds the world’s fastest AI inference technology.</p><p>The LPU™ Inference Engine by Groq is a hardware and software platform that delivers exceptional compute speed, quality, and energy efficiency.</p><p>Groq, headquartered in Silicon Valley, provides cloud and on-prem solutions at scale for AI applications. The LPU and related systems are designed, fabricated, and assembled in North America.</p><h3 id=future-directions-and-research-1>Future Directions and Research</h3><p>Looking ahead, Together AI plans to further optimize the MoA architecture by exploring various model choices, prompts, and configurations. One key area of focus will be reducing the latency of the time to the first token, which is an exciting future direction for this research. They aim to enhance MoA’s capabilities in reasoning-focused tasks, further solidifying its position as a leader in AI innovation.</p><h2 id=conclusion>Conclusion</h2><p>In conclusion, Together MoA represents a significant advancement in leveraging the collective intelligence of open-source models. Its layered approach and collaborative ethos exemplify the potential for enhancing AI systems, making them more capable, robust, and aligned with human reasoning. The AI community eagerly anticipates this groundbreaking technology’s continued evolution and application.</p><h2 id=acknowledgment-and-citation>Acknowledgment and Citation</h2><p>This blog post is based on the paper &ldquo;Mixture-of-Agents Enhances Large Language Model Capabilities&rdquo; by Junlin Wang, Jue Wang, Ben Athiwaratkun, Ce Zhang, and James Zou. The original paper can be accessed <a href=https://arxiv.org/pdf/2406.04692>here</a>. The implementation of Together MoA can be found on <a href=https://github.com/togethercomputer/MoA>Together AI&rsquo;s GitHub repository</a>. Additionally, the adaptation for Grog AI by Ray Bernard can be accessed on <a href=https://github.com/raymondbernard/moa-grog>his GitHub repository</a>.</p><hr><p>Would you like any further modifications or additions to the article?</p><h3 id=star-my-repo-please>Star my repo please</h3><p><a href=https://github.com/raymondbernard/moa-grog>Star this Repo on GitHub</a></p><h2 id=comments>Comments</h2><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://raymondbernard-github-io.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=http://localhost:1313/>&copy; Ray Bernard's Fine Tuned Journal 2024</a><div><div class=ananke-socials><a href=https://www.github.com/raymondbernard/fine-tune-journal target=_blank rel=noopener class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="github link" aria-label="follow on github——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.linkedin.com/in/raymond-bernard-960382/ target=_blank rel=noopener class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="My Linkedin link" aria-label="follow on My Linkedin——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.youtube.com/channel/UC-OszhqWsF1tqqECdeLI_7Q target=_blank rel=noopener class="youtube ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="youtube link" aria-label="follow on youtube——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M42.527 41.34c-.278.0-.478.078-.6.244-.121.156-.18.424-.18.796v.896h1.543V42.38c0-.372-.062-.64-.185-.796C42.989 41.418 42.792 41.34 42.527 41.34zM36.509 41.309c.234.0.417.076.544.23.123.155.185.383.185.682v4.584c0 .286-.053.487-.153.611-.1.127-.256.189-.47.189-.148.0-.287-.033-.421-.096-.135-.062-.274-.171-.415-.313v-5.531c.119-.122.239-.213.36-.271C36.26 41.335 36.383 41.309 36.509 41.309zm5.239 3.349v1.672c0 .468.057.792.17.974.118.181.313.269.592.269.289.0.491-.076.606-.229.114-.153.175-.489.175-1.013v-.405h1.795v.456c0 .911-.217 1.596-.657 2.059-.435.459-1.089.687-1.958.687-.781.0-1.398-.242-1.847-.731-.448-.486-.676-1.157-.676-2.014v-3.986c0-.768.249-1.398.742-1.882.493-.484 1.128-.727 1.911-.727.799.0 1.413.225 1.843.674.429.448.642 1.093.642 1.935v2.264H41.748zm-3.125 3.837c-.271.336-.669.501-1.187.501-.343.0-.646-.062-.912-.192-.267-.129-.519-.327-.746-.601v.681h-1.764V36.852h1.764v3.875c.237-.27.485-.478.748-.616.267-.143.534-.212.805-.212.554.0.975.189 1.265.565.294.379.438.933.438 1.66v4.926C39.034 47.678 38.897 48.159 38.623 48.495zM30.958 48.884v-.976c-.325.361-.658.636-1.009.822-.349.191-.686.282-1.014.282-.405.0-.705-.129-.913-.396-.201-.266-.305-.658-.305-1.189v-7.422h1.744v6.809c0 .211.037.362.107.457.077.095.196.141.358.141.128.0.292-.062.488-.188.197-.125.375-.283.542-.475v-6.744H32.7v8.878H30.958zM24.916 38.6v10.284h-1.968V38.6h-2.034v-1.748h6.036V38.6H24.916zm8.078-5.622c0-.001 12.08.018 13.514 1.45 1.439 1.435 1.455 8.514 1.455 8.555.0.0-.012 7.117-1.455 8.556C45.074 52.969 32.994 53 32.994 53s-12.079-.031-13.516-1.462c-1.438-1.435-1.441-8.502-1.441-8.556.0-.041.004-7.12 1.441-8.555 1.438-1.431 13.516-1.45 13.516-1.449zm9.526-3.723h-1.966v-1.08c-.358.397-.736.703-1.13.909-.392.208-.771.312-1.14.312-.458.0-.797-.146-1.027-.437-.229-.291-.345-.727-.345-1.311v-8.172h1.962v7.497c0 .231.045.399.127.502.08.104.216.156.399.156.143.0.327-.069.548-.206.22-.137.423-.312.605-.527v-7.422h1.966V29.255zM31.847 27.588c.139.147.339.219.6.219.266.0.476-.075.634-.223.157-.152.235-.358.235-.618v-5.327c0-.214-.08-.387-.241-.519-.16-.131-.37-.196-.628-.196-.241.0-.435.065-.586.196-.148.132-.225.305-.225.519v5.327C31.636 27.233 31.708 27.439 31.847 27.588zm-1.439-7.685c.528-.449 1.241-.674 2.132-.674.812.0 1.48.237 2.001.711.517.473.777 1.083.777 1.828v5.051c0 .836-.255 1.491-.762 1.968-.513.476-1.212.714-2.106.714-.858.0-1.547-.246-2.064-.736-.513-.492-.772-1.152-.772-1.983v-5.068C29.613 20.954 29.877 20.351 30.408 19.903zM24.262 16h-2.229l2.634 8.003v5.252h2.213v-5.5L29.454 16h-2.25l-1.366 5.298h-.139L24.262 16zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://x.com/raybernard007 target=_blank rel=noopener class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://medium.com/@raybernard007 target=_blank rel=noopener class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="twitter link" aria-label="follow on twitter——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 170 170" viewBox="0 0 170 170" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M46.5340803 65.2157554C46.6968378 63.6076572 46.0836 62.018231 44.8828198 60.93592L32.6512605 46.2010582V44H70.6302521l29.3557423 64.380952L125.794585 44H162v2.2010582L151.542017 56.2281011C150.640424 56.9153477 150.193188 58.0448862 150.380019 59.1628454V132.837155C150.193188 133.955114 150.640424 135.084652 151.542017 135.771899l10.213352 10.027043V148H110.38282V145.798942l10.580299-10.271605c1.039682-1.039389 1.039682-1.345091 1.039682-2.934744V73.0417402l-29.4169 74.7136978H88.6106443L54.3622782 73.0417402V123.115814C54.0767278 125.221069 54.7759199 127.3406 56.2581699 128.863022L70.0186741 145.55438V147.755438H31V145.55438l13.7605042-16.691358c1.4714579-1.524946 2.1298796-3.658537 1.7735761-5.747208V65.2157554z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</span></a><a href=https://www.reddit.com/user/OpenAITutor/ target=_blank rel=noopener class="reddit ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="reddit link" aria-label="follow on reddit——Opens in a new window">reddit
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>